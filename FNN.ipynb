{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network (FNN)\n",
    "\n",
    "- Feed forward neural network is the type of artificial neural network, here is the only forward neural network used to train the model and output value is produced.\n",
    "- It is the simplest type of neural network and is used for classification and regression tasks.\n",
    "- It is a multilayer neural network, where each layer is fully connected to the previous layer\n",
    "- It is used for image classification, speech recognition, and natural language processing tasks.\n",
    "- It is a type of supervised learning algorithm, where the model is trained on labeled data.\n",
    "- It is a type of deep learning algorithm, where the model is trained on a large dataset and\n",
    "uses multiple layers to learn complex patterns in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods used in Feed forward neural network (FNN):\n",
    "1. **Back Propagation (BP) Algorithm:** This is the most commonly used algorithm for training\n",
    "feedforward neural networks. It is a supervised learning method that uses the gradient descent\n",
    "algorithm to minimize the error between the network's output and the desired output.\n",
    "2. **Activation Functions:** These are mathematical functions that are applied to the output of each\n",
    "neuron to introduce non-linearity into the network. Common activation functions include the\n",
    "sigmoid function, the ReLU (Rectified Linear Unit) function, and the tanh (hyper\n",
    "function.\n",
    "3. **Weight Initialization:** This is the process of initializing the weights of the network to\n",
    "appropriate values. There are several methods for weight initialization, including random\n",
    "initialization, Xavier initialization, and Kaiming initialization.\n",
    "4. **Regularization Techniques:** These are methods used to prevent overfitting in the network.\n",
    "5. **Optimization Algorithms:** These are algorithms used to minimize the error between the network's output\n",
    "and the desired output. Common optimization algorithms include stochastic gradient descent (SGD), Adam, and RMS\n",
    "6. **Early Stopping:** This is a technique used to prevent overfitting by stopping the\n",
    "training process when the network's performance on the validation set starts to degrade.\n",
    "7. **Batch Normalization:** This is a technique used to normalize the input to each layer,\n",
    "which can help to improve the stability and speed of training.\n",
    "8. **Dropout:** This is a technique used to prevent overfitting by randomly dropping out\n",
    "neurons during training.\n",
    "9. **Gradient Clipping:** This is a technique used to prevent exploding gradients by clipping the\n",
    "gradients to a certain value.\n",
    "10. **Learning Rate Schedulers:** These are algorithms used to adjust the learning rate during training.\n",
    "11. **Data Preprocessing:** This is the process of preparing the data for training, including\n",
    "normalization, feature scaling, and encoding categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed forward neural network (FNN) model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import the Tensorflow and sklearn libraries:\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "#Keras Sequential Model with tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset:\n",
    "df = sns.load_dataset('tips')\n",
    "#Print the first 5 rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encode the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the dataset into the Label Encoder:\n",
    "le = LabelEncoder()\n",
    "df['sex'] = le.fit_transform(df['sex'])\n",
    "df['smoker'] = le.fit_transform(df['smoker'])\n",
    "df['day'] = le.fit_transform(df['day'])\n",
    "df['time'] = le.fit_transform(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the variables for binary classification:\n",
    "median_bill = df['total_bill'].median()\n",
    "df['high_bill'] = (df['total_bill'] > median_bill.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset:\n",
    "X = df.drop(['total_bill', 'high_bill'], axis=1)\n",
    "y = df['high_bill']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scale the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the features:\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed forward Neural Network Model Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "\n",
    "# Built the Feed forward neural network model\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=[X_train.shape[1]]),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model:\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.5999 - loss: 0.6609 - val_accuracy: 0.5102 - val_loss: 0.6891\n",
      "Epoch 2/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5939 - loss: 0.6447 - val_accuracy: 0.5102 - val_loss: 0.6755\n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5794 - loss: 0.6604 - val_accuracy: 0.5102 - val_loss: 0.6630\n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5816 - loss: 0.6369 - val_accuracy: 0.5102 - val_loss: 0.6519\n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5774 - loss: 0.6288 - val_accuracy: 0.5102 - val_loss: 0.6436\n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5875 - loss: 0.6359 - val_accuracy: 0.5102 - val_loss: 0.6357\n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6578 - loss: 0.5910 - val_accuracy: 0.5510 - val_loss: 0.6268\n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6853 - loss: 0.6019 - val_accuracy: 0.5714 - val_loss: 0.6182\n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6695 - loss: 0.6086 - val_accuracy: 0.6122 - val_loss: 0.6097\n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6730 - loss: 0.6018 - val_accuracy: 0.6122 - val_loss: 0.6020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x241d27bf2b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model:\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(\n",
    "    X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evalution Method for Test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6165 - loss: 0.6008 \n",
      "Test loss: 0.60%, Test acc: 0.61%\n"
     ]
    }
   ],
   "source": [
    "#Evalute the model for Test data:\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss:.2f}%, Test acc: {acc :.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evalution Method of Train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5760 \n",
      "Train loss: 0.59%, Train acc: 0.72%\n"
     ]
    }
   ],
   "source": [
    "#Evalute the model for Train data:\n",
    "val_loss, val_acc = model.evaluate(X_train, y_train)\n",
    "print(f'Train loss: {val_loss:.2f}%, Train acc: {val_acc :.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Multiclass-Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MultiClass Classification:\n",
    "X = df.drop(['day'], axis = 1)\n",
    "y = df['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique().shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
